{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6d6584",
   "metadata": {},
   "source": [
    "# Creating files with script mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bdbbe3",
   "metadata": {},
   "source": [
    "## 1. Get data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e25045cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find ../data/pizza_steak_sushi directory, creating one...\n",
      "Downloading pizza, steak, sushi data...\n",
      "Unzipping pizza, steak, sushi data...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Setting up path to data folder\n",
    "data_path = Path(\"../data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# Downloading data if it doesn't exist\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "    request = requests.get(\n",
    "        \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\"\n",
    "    )\n",
    "    print(\"Downloading pizza, steak, sushi data...\")\n",
    "    f.write(request.content)\n",
    "\n",
    "# Unzipping downloaded file\n",
    "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "    print(\"Unzipping pizza, steak, sushi data...\")\n",
    "    zip_ref.extractall(image_path)\n",
    "\n",
    "# Removing zip file\n",
    "os.remove(data_path / \"pizza_steak_sushi.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f90fc15",
   "metadata": {},
   "source": [
    "## 2. Create Datasets and DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "362c20b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../modules/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../modules/data_setup.py\n",
    "\"\"\"\n",
    "Contains functionality for creating PyTorch DataLoaders for image classification data.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_dir: str | Path,\n",
    "    test_dir: str | Path,\n",
    "    train_transform: transforms.Compose,\n",
    "    test_transform: transforms.Compose,\n",
    "    batch_size: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates training and testing DataLoaders.\n",
    "\n",
    "    Takes in a training directory and testing directory path and turns them into PyTorch Datasets\n",
    "    and then into PyTorch DataLoaders.\n",
    "\n",
    "    Args;\n",
    "        train_dir (str | Path): Path to training directory.\n",
    "        test_dir (str | Path): Path to testing directory.\n",
    "        train_transform (transforms.Compose): `torchvision` transforms to perform on training data data.\n",
    "        test_transform (transforms.Compose): `torchvision` transforms to perform on testing data.\n",
    "        batch_size (int): Number of samples per batch in each of the DataLoaders.\n",
    "\n",
    "    Returns:\n",
    "        `Tuple[DataLoader,DataLoader,str]`: A tuple of `(train_dataloader, test_dataloader, class_names)`,\n",
    "        where `class_names` is a list of the target classes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Using ImageFolder to create datasets\n",
    "    train_data = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "    test_data = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "\n",
    "    # Getting class names\n",
    "    class_names = train_data.classes\n",
    "\n",
    "    # Turn images into dataloaders\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset=test_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc6c6b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../modules/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../modules/model_builder.py\n",
    "\n",
    "\"\"\"\n",
    "Contains PyTorch model code to instantiate a TinyVGG model.\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates the TinyVGG architecture.\n",
    "\n",
    "    Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
    "    The original architecture can be found here: https://poloclub.github.io/cnn-explainer/\n",
    "\n",
    "    Args:\n",
    "        input_shape (int): An integer indicating number of input channels.\n",
    "        hidden_units: An integer indicating number of hidden units between layers.\n",
    "        output_shape: An integer indicating number of output units.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.classifier(self.conv_block_2(self.conv_block_1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228ee24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../modules/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../modules/engine.py\n",
    "\n",
    "\"\"\"\n",
    "Contains functions for training and testing a PyTorch model.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "def train_step(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: str,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Trains a PyTorch model for a single epoch.\n",
    "\n",
    "    Turns a target PyTorch model to training mode then runs through all of the required training steps\n",
    "    (forward pass, loss calculation, optimizer step).\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model to be trained.\n",
    "        dataloader (torch.utils.data.DataLoader): A DataLoader instance for the model to be trained on.\n",
    "        loss_fn (torch.nn.Module): A PyTorch loss function to minimize.\n",
    "        optimizer (torch.optim.Optimizer): A PyTorch optimizer to help minimize the loss function.\n",
    "        device (str): A target device's name to compute on.\n",
    "\n",
    "    Returns:\n",
    "        `Tuple[float,float]`: Tuple of training loss and training accuracy metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item() / len(y_pred)\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def test_step(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: str,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Tests a PyTorch model for a single epoch.\n",
    "\n",
    "    Turns a target PyTorch model to eval mode then runs through forward pass on test dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model to be trained.\n",
    "        dataloader (torch.utils.data.DataLoader): A DataLoader instance for the model to be tested on.\n",
    "        loss_fn (torch.nn.Module): A PyTorch loss function to calculate loss on test data.\n",
    "        device (str): A target device's name to compute on.\n",
    "\n",
    "    Returns:\n",
    "        `Tuple[float,float]`: Tuple of testing loss and testing accuracy metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += (test_pred_labels == y).sum().item() / len(test_pred_labels)\n",
    "\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n",
    "    epochs: int = 5,\n",
    "    device: str = \"cpu\",\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Trains a PyTorch model for a single epoch.\n",
    "\n",
    "    Turns a target PyTorch model to training mode then runs through all of the required training steps\n",
    "    (forward pass, loss calculation, optimizer step).\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model to be trained.\n",
    "        train_dataloader (torch.utils.data.DataLoader): A DataLoader instance for the model to be trained on.\n",
    "        test_dataloader (torch.utils.data.DataLoader): A DataLoader instance for the model to be tested on.\n",
    "        optimizer (torch.optim.Optimizer): A PyTorch optimizer to help minimize the loss function.\n",
    "        loss_fn (torch.nn.Module): A PyTorch loss function to minimize.\n",
    "        device (str): A target device's name to compute on.\n",
    "\n",
    "    Returns:\n",
    "        `Dict[str,List[float]]`: Dictionary of training and testing loss, as well as training and testing\n",
    "        accuracy metrics. Each metric has a value in a list for each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_acc\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "        )\n",
    "        test_loss, test_acc = test_step(\n",
    "            model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"\"\"\n",
    "======================================      \n",
    "Epoch:                       |   {epoch + 1}   |  \n",
    "======================================      \n",
    "Train Loss:                  | {train_loss:.3f} |\n",
    "\n",
    "Train Accuracy:              | {train_acc:.3f} |            \n",
    "--------------------------------------\n",
    "Test Loss:                   | {test_loss:.3f} |\n",
    "\n",
    "Test Accuracy:               | {test_acc:.3f} |\n",
    "              \"\"\"\n",
    "        )\n",
    "\n",
    "        results[\"train_loss\"].append(\n",
    "            train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss\n",
    "        )\n",
    "        results[\"train_acc\"].append(\n",
    "            train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc\n",
    "        )\n",
    "        results[\"test_loss\"].append(\n",
    "            test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss\n",
    "        )\n",
    "        results[\"test_acc\"].append(\n",
    "            test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc\n",
    "        )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "685c4140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../modules/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../modules/utils.py\n",
    "\"\"\"\n",
    "Contains various utility functions for PyTorch model training and saving.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def save_model(model: torch.nn.Module, target_dir: str | Path, model_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves a PyTorch model to a target directory.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model to save.\n",
    "        target_dir (str | Path): Directory in which the model should be saved.\n",
    "        model_name (str): The filename for the saved model. Should include either\n",
    "        \".pth\" or \".pt\" as the file extension\n",
    "    \"\"\"\n",
    "    target_dir_path = target_dir\n",
    "    if not isinstance(target_dir_path, Path):\n",
    "        target_dir_path = Path(target_dir)\n",
    "        \n",
    "    target_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\n",
    "        \".pt\"\n",
    "    ), \"model_name should end with '.pt' or '.pth'.\"\n",
    "    model_save_path = target_dir_path / model_name\n",
    "\n",
    "    print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "    torch.save(obj=model.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9915779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../modules/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../modules/train.py\n",
    "\"\"\"\n",
    "Trains a PyTorch image classification model using device-agnostic code.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import data_setup, engine, model_builder, utils\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "# Setup hyperparameters\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_UNITS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Setup directories\n",
    "train_dir = \"../data/pizza_steak_sushi/train\"\n",
    "test_dir = \"../data/pizza_steak_sushi/test\"\n",
    "\n",
    "# Setup target device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Creating transforms\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Creating DataLoaders with helps from data_setup.py\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    train_transform=data_transform,\n",
    "    test_transform=data_transform,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# Creating model with help from model_builder.py\n",
    "model = model_builder.TinyVGG(\n",
    "    input_shape=3, hidden_units=HIDDEN_UNITS, output_shape=len(class_names)\n",
    ").to(device)\n",
    "\n",
    "# Setting up loss and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Start training with help from engine.py\n",
    "engine.train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Saving model with help from utils.py\n",
    "utils.save_model(model=model, target_dir=\"models\", model_name=\"script_mode.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2f631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
